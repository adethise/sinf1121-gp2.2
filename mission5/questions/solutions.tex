\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}


\date{21 novembre 2014}
\author{Groupe 2.2}
\title{Produit Mission 5}

\begin{document}
\maketitle

\section*{Question 1 Aurian de Potter}
\section*{Question 2 Romain Henneton}
L'algorithme de Knuth-Morris-Pratt (KMP) un un algorithme permettant de résoudre un problème appelé "pattern matching problem" sur un String, en général. Soit un texte P (pattern) de longeur m et un autre texte T de longueur n (avec m$\leq$n). L'algorithme KMP va permettre soit de déterminer si le pattern P figure dans le texte T et à quelle position, soit, le cas échéant, de déternimer que P ne figure pas dans T.



L'algorithme de brute force correspondant à cette recherche de pattern matching est constitué de deux boucles impriquées. La première (externe) parcourant les indices de T de 0 à n-m (via l'incrément i par exemple). La seconde (interne à la première), parcourant tous les éléments de P et comparant $T[i+j]$ ($0\leq j\leq n$) avec P$[j]$. La complexité de cette algorithme dans le pire des cas est donc O((n-m+1)n), donc O(nm).\\
L'algorithme de Knuth-Morris-Pratt est une variante améliorée de cette méthode de brute force. Lorsqu'un caractère ne correspondant pas au texte P est rencontré, plutot que de retourner à l'élément i+1 et de relancer la comparaison sur m, l'algorithme KMP va exploiter les comparaisons déjà réalisées et lancer la nouvelle recherche à un indice plus approprié et déterminé grâce à un pré-traitement de P. Ce pré-traitement est réalisé via une fonction appelée "Failure Function" qui associe à chaque indice de P une valeur définie comme le plus long préfixe P correspondant au sufixe de P[1..j]. Cela permet de redémarrer à un indice plus intéressant et d'éviter des comparaisons inutiles. La complexitée  est de O(n+m).
\section*{Question 3 Jérôme Lemaire}

\section*{Question 4 Zacharie Kerger}

Une file de priorité adaptable est une file de priorité possédant 3 méthodes supplémentaires: remove(e), replaceKey(e,k) et replaceValue(e,v). Il n'est pas plus avantageux d'utiliser ce type de file de priorité pour la construction d'un code de Huffman parce que le calcul de la fréquence est réalisé dès le début de l'algorithme. Dès lors, ces trois méthodes n'auront aucune utilité puisque les entrées, les valeurs et les clés des entrées sont connues et ne changeront pas. Le code de Huffman va juste fusionner les différents noeuds sans les modifier.\\

L’utilisation d’une file de priorité n’est pas indispensable pour construire un code de Huffman. Il est possible d'en construire un avec un algorithme de tri. 

\begin{enumerate}
\item On calcule la fréquence de chaque caractère (complexité de $\Theta(n)$ où n représente la taille du String à compresser) et on les ajoute dans une liste triée dans un ordre croissant (complexité de $O(d^{2})$ où d représente les caractères distincts du String à compresser).
\item On additionne les fréquences des deux premières entrées (que l'on retire de la liste) et on construit un noeud possédant comme fils gauche, l'entrée qui a la plus petite fréquence et comme fils droit, l'entrée qui a la plus grande fréquence.
\item Le noeud créé est représenté par une entrée ayant comme clé l'addition réalisée à l'étape précédente. 
\item On ajoute l'entrée créée précédemment, à la liste triée.
\item On répète les étapes 2, 3 et 4 tant qu'il reste plus d'un élément dans la liste (complexité de $O(d^{2})$). 
\item A cette étape, il ne reste qu'une seule entrée qui représente la racine de l'arbre de Huffman.
\end{enumerate}

La complexité calculatoire sera plus élevée que celle de l'algorithme original. En effet, pour insérer \underline{un} élément dans une liste triée, nous avons une complexité temporelle de $O(n)$ vu que dans le pire des cas, on devra parcourir toute la liste de n éléments. Dès lors, on obtient une complexité temporelle équivalente à $O(n + d^2)$ (voir calculs dans la description de la méthode ci-dessus) alors que nous avons une complexité de $O(n+d\log d)$ avec l'algorithme original.

\section*{Question 5 Arnaud Dethise}

	Le code de Huffman permet de compresser un texte encodé par exemple en ASCII ou en Unicode en un fichier binaire plus léger. Cette compression se base sur des mots-code qui représentent chaque caractère sur un nombre variable de bits, et non sur 7, 8, 16 ou même 64 bits.
	
	Pour cela, il faut d'abord construire l'arbre de Huffman. L'algorithme complet se trouve dans le DSAJ6-p519. Les étapes et complexités associées sont les suivantes ($n$ est la longueur de la chaîne de caractères ; $d$ est le nombre de caractères différents).
	\vspace{0.3cm}
	
	\begin{enumerate}
	\item[1.] Calculer la fréquence d'apparition de chaque caractère de l'input : $\Theta(n)$.
	\item[2.] Créer la \textit{file de priorité}. Il faut créer un arbre d'un seul nœud par caractère pour $d$ caractères et l'ajouter à la file avec sa fréquence comme clé : $\Theta(d)$.
	\item[3.] Récupérer $E_1$ et $E_2$, les deux éléments de la file dont la clé est minimale : $\Theta(2d)$.
	\item[4.] Créer un nouvel arbre dont la racine est un nœud ayant $E_1$ et $E_2$ comme enfants et le replacer dans la file avec pour clé la somme des anciennes clés de $E_1$ et $E_2$ : $\mathcal{O}(1)$.
	\item[5.] S'il y a plus d'un élément dans la file, recommencer à [3]. Sinon, retourner le dernier élément : $\Theta(d*[3-5])$.
	\end{enumerate}
	\vspace{0.3cm}
	
	La complexité de cet algorithme est de $\Theta(n + d^2)$. On peut toutefois l'optimiser :
	\vspace{0.3cm}
	
	\begin{enumerate}
	\item[2.5] Trier la file de priorité : $\mathcal{O}(d $ log $d)$.
	\item[4.] Devient : Placer le nouvel arbre dans la file en gardant celle-ci triée : $\mathcal{O}($log $d)$.
	\item[3.] Devient : $\mathcal{O}(1)$.
	\end{enumerate}
	\vspace{0.3cm}
	
	Et on obtient alors une complexité pour la création de l'arbre de $\mathcal{O}(n + d $ log $ d)$.
	
	Une fois l'arbre construit, on peut le parcourir pour créer un mapping entre chaque caractère et le mot-code qui lui est associé. 
	Il s'agit d'un simple parcours de chaque nœud de l'arbre et une implémentation efficace aura une complexité $\Theta(d)$. 
	Il est logique d'utiliser une HashMap à cette étape puisque l'on voudra accéder à chaque élément indépendamment en $\mathcal{O}(1)$.
	
	Enfin, on peut maintenant parcourir la chaîne de caractère d'entrée caractère par caractère et concaténer à la chaîne de bits de sortie à chaque fois la séquence de bit correspondante (récupérée depuis la HashMap). 
	On peut évaluer cette opération comme étant en $\Theta(n)$ (bien qu'il soit possible  d'affiner l'analyse en fonction de l'encodage ou du nombre de caractères différents, on considère ici que le décodage d'un caractère et l'ajout d'une séquence de bits sont des opérations en temps constant).
	
	\vspace{0.3cm}
	Au final, la complexité de la compression complète est de $\mathcal{O}(n + d $ log $ d) + \Theta(d) + \Theta(n)$, soit en suivant la notation asymptotique $\mathcal{O}(n + d $ log $ d)$.
	

\section*{Question 6 Arnaud Dethise}

	Pour la décompression d'un texte, il y a deux étapes principales : reconstruire la table d'association caractère~/~mot-code, puis utiliser celle-ci pour lire le fichier binaire.
	
	La première étape dépend de la façon dont la table est transmise. Intuitivement, on peut supposer qu'il soit possible de recréer une table avec une complexité en $\Theta(d)$, $d$ le nombre de caractères différents.
	
	Ensuite il faut lire le fichier, bit par bit, et en extraire les séquences qui sont présentes dans le dictionnaire.
	Il faut dans ce cas vérifier à chaque bit lu si on peut extraire un caractère des derniers bits lus. Autrement dit, il faut vérifier si on match un caractère à chaque bit, ce qui donne une complexité de $\Theta(l)$ où $l$ est la longueur du fichier en bits.


%\section*{Question 7 Romain Henneton}
%\section*{Question 8 Zacharie Kerger}
%\section*{Question 9 Aurian de Potter}
%\section{Question 10 Jérome Lemaire}
% add sections if more questions

\end{document}
